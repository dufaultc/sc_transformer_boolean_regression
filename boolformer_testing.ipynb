{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded noiseless model\n",
      "Loaded noisy model\n"
     ]
    }
   ],
   "source": [
    "from boolformer import load_boolformer\n",
    "boolformer_noiseless = load_boolformer('noiseless')\n",
    "boolformer_noisy     = load_boolformer('noisy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[False, False],\n",
       " [False, False],\n",
       " [False, False],\n",
       " [False, False],\n",
       " [False, False],\n",
       " [False, False],\n",
       " [False, False],\n",
       " [False, False],\n",
       " [False, False],\n",
       " [False, False]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[False, False]]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "inputs = np.array(\n",
    "    [[False, False]]*10000\n",
    ")\n",
    "outputs1 = np.array([False, False, False, True]*2000)\n",
    "outputs2 = np.array([True, False, False, True]*2000)\n",
    "inputs = [inputs, inputs]\n",
    "outputs = [outputs1, outputs2]\n",
    "pred_trees, errors, complexities = boolformer_noisy.fit(inputs, outputs, verbose=False, beam_size=10, beam_type=\"search\")\n",
    "\n",
    "for pred_tree in pred_trees:\n",
    "    print(pred_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [True, False]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: nvidia-smi: not found\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader' returned non-zero exit status 127.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m free_gpus\n\u001b[1;32m     48\u001b[0m \u001b[39m# Get the list of free GPUs\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m free_gpus \u001b[39m=\u001b[39m get_free_gpus()\n\u001b[1;32m     50\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFree GPUs: \u001b[39m\u001b[39m\"\u001b[39m,free_gpus)\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m free_gpus:\n",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m, in \u001b[0;36mget_free_gpus\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_free_gpus\u001b[39m():\n\u001b[0;32m---> 34\u001b[0m     output \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mcheck_output(\u001b[39m\"\u001b[39m\u001b[39mnvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader\u001b[39m\u001b[39m\"\u001b[39m, shell\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m     free_memory \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mdecode()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)]\n\u001b[1;32m     36\u001b[0m     free_gpus \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i, memory \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(free_memory) \u001b[39mif\u001b[39;00m memory \u001b[39m>\u001b[39m \u001b[39m10000\u001b[39m]  \u001b[39m# Change the threshold based on your needs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cam_env_2/lib/python3.11/subprocess.py:466\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         empty \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    464\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m empty\n\u001b[0;32m--> 466\u001b[0m \u001b[39mreturn\u001b[39;00m run(\u001b[39m*\u001b[39mpopenargs, stdout\u001b[39m=\u001b[39mPIPE, timeout\u001b[39m=\u001b[39mtimeout, check\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    467\u001b[0m            \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/miniconda3/envs/cam_env_2/lib/python3.11/subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     retcode \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mpoll()\n\u001b[1;32m    570\u001b[0m     \u001b[39mif\u001b[39;00m check \u001b[39mand\u001b[39;00m retcode:\n\u001b[0;32m--> 571\u001b[0m         \u001b[39mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[39m.\u001b[39margs,\n\u001b[1;32m    572\u001b[0m                                  output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n\u001b[1;32m    573\u001b[0m \u001b[39mreturn\u001b[39;00m CompletedProcess(process\u001b[39m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader' returned non-zero exit status 127."
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from subprocess import DEVNULL\n",
    "import os\n",
    "import re\n",
    "from time import sleep\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from distutils import dir_util\n",
    "user = 'cameron'\n",
    "\n",
    "exp_folder = 'noisy'\n",
    "\n",
    "dump_path = f'/home/{user}/odeformer/experiments'\n",
    "Path(dump_path).mkdir(exist_ok=True)\n",
    "\n",
    "extra_args = {\n",
    "    \"min_active_vars\":1,\n",
    "    \"min_points\":30,\n",
    "    \"max_points\":600,\n",
    "    \"input_truth_table\":False,\n",
    "    \"max_flip_prob\":0.1,\n",
    "    \"enc_emb_dim\":512,\n",
    "    \"n_enc_layers\":8,\n",
    "    \"max_active_vars\":100,\n",
    "    \"max_inactive_vars\":120,\n",
    "    }\n",
    "\n",
    "grid = {\n",
    "    \"max_ops\":[20],\n",
    "}\n",
    "\n",
    "def get_free_gpus():\n",
    "    output = subprocess.check_output(\"nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader\", shell=True)\n",
    "    free_memory = [int(x) for x in output.decode().strip().split('\\n')]\n",
    "    free_gpus = [i for i, memory in enumerate(free_memory) if memory > 10000]  # Change the threshold based on your needs\n",
    "    free_gpus = sorted(free_gpus, key=lambda i: free_memory[i], reverse=True)\n",
    "    return free_gpus\n",
    "\n",
    "def get_most_free_gpu():\n",
    "    output = subprocess.check_output(\"nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader\", shell=True)\n",
    "    free_memory = [int(x) for x in output.decode().strip().split('\\n')]\n",
    "    most_free = free_memory.index(max(free_memory))\n",
    "    # set visible devices to the most free gpu\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(most_free)\n",
    "    return free_gpus\n",
    "\n",
    "# Get the list of free GPUs\n",
    "free_gpus = get_free_gpus()\n",
    "print(\"Free GPUs: \",free_gpus)\n",
    "if not free_gpus:\n",
    "    print(\"No free GPUs available!\")\n",
    "    exit()\n",
    "\n",
    "# Path to your PyTorch script\n",
    "pytorch_script = \"train.py\"\n",
    "\n",
    "# Function to run the PyTorch script with a specific learning rate on a specific GPU\n",
    "def run_experiment(gpu_id, args, logfile):\n",
    "    env_vars = os.environ.copy()\n",
    "    env_vars[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    command = [\"python\", pytorch_script]\n",
    "    for arg, value in args.items():\n",
    "        command.append(f\"--{arg}\")\n",
    "        command.append(str(value))\n",
    "    with open(logfile, 'a') as f:\n",
    "        subprocess.Popen(command, env=env_vars, stdout=DEVNULL, stderr=f)\n",
    "\n",
    "def dict_product(d):\n",
    "    keys = d.keys()\n",
    "    for element in itertools.product(*d.values()):\n",
    "        yield dict(zip(keys, element))\n",
    "\n",
    "for params in dict_product(grid):\n",
    "    if not free_gpus:\n",
    "        break\n",
    "    exp_id = 'exp_'+'_'.join(['{}_{}'.format(k,v) for k,v in params.items()])\n",
    "    params['dump_path'] = dump_path\n",
    "    params['exp_name'] = exp_folder\n",
    "    params['exp_id'] = exp_id\n",
    "\n",
    "    params['dec_emb_dim'] = params['enc_emb_dim']\n",
    "    params['n_dec_layers'] = params['n_enc_layers']\n",
    "    \n",
    "    job_dir = Path(os.path.join(dump_path, exp_folder, exp_id))\n",
    "    job_dir.parent.mkdir(exist_ok=True)\n",
    "    job_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for arg, value in extra_args.items():\n",
    "        if arg not in params:\n",
    "            params[arg] = value\n",
    "\n",
    "    for f in os.listdir():\n",
    "        if f.endswith('.py'):\n",
    "            shutil.copy2(f, job_dir)\n",
    "    dir_util.copy_tree('boolformer', os.path.join(job_dir,'boolformer'))\n",
    "    os.chdir(job_dir)\n",
    "\n",
    "    logfile = os.path.join(job_dir,'train.log')\n",
    "    gpu_id = free_gpus.pop(0)\n",
    "    print(f\"Starting experiment {exp_id} on GPU: {gpu_id}\")\n",
    "    run_experiment(gpu_id, params, logfile)\n",
    "    sleep(1)\n",
    "\n",
    "print(\"All experiments started.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export PATH=/usr/lib/wsl/lib:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cam_env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
